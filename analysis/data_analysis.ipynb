{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to analyze IFWASTE-Simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/blue/carpena/haasehelen/ifwaste/data/\"\n",
    "CONFIG_PATH = \"/blue/carpena/haasehelen/ifwaste/model/config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading necessary parameters from config file\n",
    "- weights per serving of each food category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FGMEAT_KG = FGDAIRY_KG = FGBAKED_KG = FGVEGETABLE_KG = FGDRYFOOD_KG = FGSNACKS_KG = FGSTOREPREPARED_KG = None\n",
    "with open(CONFIG_PATH) as f:\n",
    "    config = json.load(f)\n",
    "    FGMEAT_KG = config[\"Food\"][\"FGMeat\"][\"kg_per_serving\"]\n",
    "    FGDAIRY_KG = config[\"Food\"][\"FGDairy\"][\"kg_per_serving\"]\n",
    "    FGBAKED_KG = config[\"Food\"][\"FGBaked\"][\"kg_per_serving\"]\n",
    "    FGVEGETABLE_KG = config[\"Food\"][\"FGVegetable\"][\"kg_per_serving\"]\n",
    "    FGDRYFOOD_KG = config[\"Food\"][\"FGDryFood\"][\"kg_per_serving\"]\n",
    "    FGSNACKS_KG = config[\"Food\"][\"FGSnacks\"][\"kg_per_serving\"]\n",
    "    FGSTOREPREPARED_KG = config[\"Food\"][\"FGStorePrepared\"][\"kg_per_serving\"]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df = pd.DataFrame({\n",
    "    'Type': ['Meat & Fish', 'Dairy & Eggs', 'Fruits & Vegetables', 'Dry Foods', 'Baked Goods' ,\n",
    "    'Snacks, Condiments, Oils & Other', 'Store-Prepared Items'],\n",
    "    'Servings_to_Kg': [FGMEAT_KG, FGDAIRY_KG, FGVEGETABLE_KG, FGDRYFOOD_KG, FGBAKED_KG, FGSNACKS_KG, FGSTOREPREPARED_KG],\n",
    "    \"Color\": [\"#116A65\", \"#00a0e1\", \"#466eb4\", \"#e6a532\", \"#d7642c\",\"#73B55B\", \"#D82E5E\"]\n",
    "})\n",
    "\n",
    "status_colors = {\n",
    "            \"Inedible Parts\": \"#26547C\",\n",
    "            \"Plate Waste\": \"#FFD166\",\n",
    "            \"Spoiled Food\": \"#EF476F\"\n",
    "        }\n",
    "    \n",
    "#color_mapping = dict(zip(lookup_df['Type'], lookup_df['Color']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data() -> dict[str, dd.DataFrame]:\n",
    "    # Dictionary to store DataFrames by main folder and CSV file type\n",
    "    dataframes = {}\n",
    "\n",
    "    # List of the main folders to process\n",
    "    main_folders = [f for f in os.listdir(PATH) if os.path.isdir(os.path.join(PATH, f))]\n",
    "    df_dict = dict()\n",
    "\n",
    "    # Iterate over each main folder\n",
    "    for main_folder in main_folders:\n",
    "        folder_path = os.path.join(PATH, main_folder) # type: ignore\n",
    "        # Iterate over each run folder inside the main folder\n",
    "        for run_folder in os.listdir(folder_path):\n",
    "            run_path = os.path.join(folder_path, run_folder)\n",
    "            if os.path.isdir(run_path):\n",
    "                run_id = run_folder.split('_')[-1]  # Extract the run ID from the folder name\n",
    "                # Read each CSV type and append the DataFrame to the respective list\n",
    "                file_names = [f for f in os.listdir(os.path.join(folder_path, run_folder)) if os.path.isfile(os.path.join(folder_path,run_folder, f))]\n",
    "                for file in file_names:\n",
    "                    file_path = os.path.normpath(os.path.join(run_path, file))\n",
    "                    if os.path.exists(file_path):\n",
    "                        # Read the CSV file into a Dask DataFrame\n",
    "                        df = dd.read_csv(file_path)\n",
    "                        df_dict.setdefault(file[:-4], []).append(df)\n",
    "        # Combine all runs into a single DataFrame for each CSV type\n",
    "        combined_dfs = {csv_type: dd.concat(df_list, axis=0, ignore_index=True) \n",
    "                        for csv_type, df_list in df_dict.items()}\n",
    "        \n",
    "        # Store the combined DataFrames in the main dictionary under the main folder key\n",
    "        dataframes[main_folder] = combined_dfs\n",
    "\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: pyarrow>=10.0.1 is required for PyArrow backed StringArray.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/io/csv.py:779\u001b[0m, in \u001b[0;36mmake_reader.<locals>.read\u001b[0;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\n\u001b[1;32m    767\u001b[0m     urlpath,\n\u001b[1;32m    768\u001b[0m     blocksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    778\u001b[0m ):\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m        \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m        \u001b[49m\u001b[43massume_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massume_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_path_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_path_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/io/csv.py:676\u001b[0m, in \u001b[0;36mread_pandas\u001b[0;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    669\u001b[0m     [\n\u001b[1;32m    670\u001b[0m         [convert_legacy_task(k, ts, {}) \u001b[38;5;28;01mfor\u001b[39;00m k, ts \u001b[38;5;129;01min\u001b[39;00m dsk\u001b[38;5;241m.\u001b[39mdask\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m values\n\u001b[1;32m    674\u001b[0m ]\n\u001b[0;32m--> 676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtext_blocks_to_pandas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecified_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecified_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43murlpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/io/csv.py:395\u001b[0m, in \u001b[0;36mtext_blocks_to_pandas\u001b[0;34m(reader, block_lists, header, head, kwargs, enforce, specified_dtypes, path, blocksize, urlpath)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Construct the output collection with from_map\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCSVFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mread-csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murlpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduces_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/io/io.py:1116\u001b[0m, in \u001b[0;36mfrom_map\u001b[0;34m(func, args, meta, divisions, label, token, enforce_metadata, *iterables, **kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m graph \u001b[38;5;241m=\u001b[39m HighLevelGraph\u001b[38;5;241m.\u001b[39mfrom_collections(name, layer, dependencies\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_dd_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdivisions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/core.py:8275\u001b[0m, in \u001b[0;36mnew_dd_object\u001b[0;34m(dsk, name, meta, divisions, parent_meta)\u001b[0m\n\u001b[1;32m   8274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_parallel_type(meta):\n\u001b[0;32m-> 8275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_parallel_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdivisions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_arraylike(meta) \u001b[38;5;129;01mand\u001b[39;00m meta\u001b[38;5;241m.\u001b[39mshape:\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/core.py:4838\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, dsk, name, meta, divisions)\u001b[0m\n\u001b[1;32m   4837\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dsk, name, meta, divisions):\n\u001b[0;32m-> 4838\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdivisions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdask\u001b[38;5;241m.\u001b[39mlayers[name]\u001b[38;5;241m.\u001b[39mcollection_annotations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/core.py:476\u001b[0m, in \u001b[0;36m_Frame.__init__\u001b[0;34m(self, dsk, name, meta, divisions)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    469\u001b[0m     is_object_string_dataframe,\n\u001b[1;32m    470\u001b[0m     is_object_string_index,\n\u001b[1;32m    471\u001b[0m     is_object_string_series,\n\u001b[1;32m    472\u001b[0m     to_pyarrow_string,\n\u001b[1;32m    473\u001b[0m )\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 476\u001b[0m     \u001b[43mis_object_string_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_object_string_series(meta)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m is_object_string_index(meta)\n\u001b[1;32m    479\u001b[0m ):\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# this is an internal call, and if we enforce metadata,\u001b[39;00m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# it may interfere when reading csv with enforce=False\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_partitions(\n\u001b[1;32m    483\u001b[0m         to_pyarrow_string, enforce_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, token\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_pyarrow_string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     )\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/_pyarrow.py:54\u001b[0m, in \u001b[0;36mis_object_string_dataframe\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_object_string_dataframe\u001b[39m(x):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m---> 54\u001b[0m         \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_object_string_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_object_string_index(x\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     56\u001b[0m     )\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/_pyarrow.py:54\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_object_string_dataframe\u001b[39m(x):\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, pd\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m---> 54\u001b[0m         \u001b[38;5;28many\u001b[39m(\u001b[43mis_object_string_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _, s \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_object_string_index(x\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     56\u001b[0m     )\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/_pyarrow.py:48\u001b[0m, in \u001b[0;36mis_object_string_series\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_object_string_series\u001b[39m(x):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, pd\u001b[38;5;241m.\u001b[39mSeries) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m---> 48\u001b[0m         \u001b[43mis_object_string_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m is_object_string_index(x\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     49\u001b[0m     )\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/_pyarrow.py:29\u001b[0m, in \u001b[0;36mis_object_string_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# in pandas < 2.0, is_string_dtype(DecimalDtype()) returns True\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_string_dtype(dtype)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_pyarrow_string_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_dtype_equal(dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecimal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m )\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/dataframe/_pyarrow.py:21\u001b[0m, in \u001b[0;36mis_pyarrow_string_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m (\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStringDtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, pd\u001b[38;5;241m.\u001b[39mArrowDtype(pa\u001b[38;5;241m.\u001b[39mstring()))\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/pandas/core/arrays/string_.py:131\u001b[0m, in \u001b[0;36mStringDtype.__init__\u001b[0;34m(self, storage)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m storage \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow_numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m pa_version_under10p1:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow>=10.0.1 is required for PyArrow backed StringArray.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage \u001b[38;5;241m=\u001b[39m storage\n",
      "\u001b[0;31mImportError\u001b[0m: pyarrow>=10.0.1 is required for PyArrow backed StringArray.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/backends.py:140\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask_expr/_collection.py:5142\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(path, header, dtype_backend, storage_options, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5141\u001b[0m     path \u001b[38;5;241m=\u001b[39m stringify_path(path)\n\u001b[0;32m-> 5142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mReadCSV\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpandas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5150\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5151\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask_expr/_collection.py:4835\u001b[0m, in \u001b[0;36mnew_collection\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create new collection from an expr\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4835\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[43mexpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_meta\u001b[49m\n\u001b[1;32m   4836\u001b[0m expr\u001b[38;5;241m.\u001b[39m_name  \u001b[38;5;66;03m# Ensure backend is imported\u001b[39;00m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask_expr/io/csv.py:95\u001b[0m, in \u001b[0;36mReadCSV._meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ddf\u001b[49m\u001b[38;5;241m.\u001b[39m_meta\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[0;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask_expr/io/csv.py:85\u001b[0m, in \u001b[0;36mReadCSV._ddf\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     columns \u001b[38;5;241m=\u001b[39m usecols\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/backends.py:151\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: pyarrow>=10.0.1 is required for PyArrow backed StringArray.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_path, file))\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[1;32m     22\u001b[0m                 \u001b[38;5;66;03m# Read the CSV file into a Dask DataFrame\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m                 df \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m                 df_dict\u001b[38;5;241m.\u001b[39msetdefault(file[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m], [])\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Combine all runs into a single DataFrame for each CSV type\u001b[39;00m\n",
      "File \u001b[0;32m/blue/carpena/haasehelen/.conda/envs/ifwaste-env/lib/python3.12/site-packages/dask/backends.py:151\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: pyarrow>=10.0.1 is required for PyArrow backed StringArray."
     ]
    }
   ],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifwaste-env-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
